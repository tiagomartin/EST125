---
title: 'Data Leakage: um problema invis√≠vel que pode comprometer seu projeto de machine
  learning'
author: Tiago Pereira
date: '2023-05-23'
slug: data-leakage
categories:
  - Conceitos
  - Pr√©-processamento
  - Data Leakage
tags:
  - Conceitos
  - EDA
subtitle: 'O vazamento de dados √© uma vulnerabilidade que compromete a confiabilidade das m√©tricas de avalia√ß√£o do modelo, levando a resultados question√°veis e imprecisos.'
summary: 'O vazamento de dados √© uma vulnerabilidade que compromete a confiabilidade das m√©tricas de avalia√ß√£o do modelo, levando a resultados question√°veis e imprecisos.'
authors: []
lastmod: '2023-05-23T14:27:04-03:00'
featured: no
draft: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

Ol√° pessoal, beleza?

Hoje vamos falar sobre um problema muitas vezes n√£o detectado, mas que pode comprometer, e muito, os resultados de seu modelo preditivo: o vazamento de dados!

Analisar dados tornou-se uma pe√ßa fundamental para o sucesso das empresas em um mundo cada vez mais orientado por dados. A capacidade de extrair insights valiosos a partir de dados tem impulsionado a tomada de decis√µes e melhorado os resultados em v√°rias organiza√ß√µes. No entanto, um desafio cr√≠tico enfrentado nesses projetos √© o vazamento de dados, conhecido como _"data leakage"_. 

Neste post, exploraremos como realizar uma an√°lise de dados de forma a evitar o data leakage, garantindo a integridade e a confiabilidade dos modelos de machine learning.

## O que √© Data Leakage?

Antes de mais nada, √© fundamental compreendermos o conceito de "vazamento de dados". O _data leakage_ ocorre quando informa√ß√µes que n√£o estariam dispon√≠veis durante o uso pr√°tico do modelo s√£o acidentalmente inclu√≠das no processo de treinamento ou valida√ß√£o. Isso pode levar a resultados ilusoriamente bons durante a fase de desenvolvimento, mas que se mostram ineficazes quando o modelo √© aplicado a novos dados. O vazamento de dados √© um desafio complexo, pois muitas vezes √© sutil e dif√≠cil de detectar. Compreender suas formas e causas √© essencial para evitar resultados distorcidos.


## O que pode causar Data Leakage?

Existem v√°rias causas comuns de data leakage, e √© essencial identific√°-las para evitar sua ocorr√™ncia. Vamos listar as mais comuns...

#### Data Leakage Temporal: Quando o tempo √© um fator cr√≠tico

Em muitos casos, os dados est√£o organizados em ordem cronol√≥gica, e √© importante respeitar essa estrutura durante a divis√£o dos conjuntos de treinamento, valida√ß√£o e teste. Vazar dados futuros para o conjunto de treinamento pode levar a um modelo enviesado, uma vez que ele ter√° acesso a informa√ß√µes que n√£o estariam dispon√≠veis no mundo real.
  
#### Data Leakage de Fonte: Quando a fonte dos dados √© comprometida 

Ocorre quando as informa√ß√µes provenientes de fontes n√£o dispon√≠veis no momento da previs√£o s√£o inclu√≠das no conjunto de treinamento. O conjunto de teste deve ser usado apenas para avaliar o desempenho final do modelo, e n√£o para tomar decis√µes no processo de desenvolvimento. Utilizar informa√ß√µes do conjunto de teste, como estat√≠sticas descritivas ou vari√°veis criadas a partir desses dados, pode levar a um modelo superestimado. 

#### Data Leakage de Alvo: Quando o pr√≥prio alvo est√° vazando informa√ß√µes

Esse tipo de vazamento ocorre quando o pr√≥prio alvo (vari√°vel a ser prevista) cont√©m informa√ß√µes que n√£o devem estar dispon√≠veis no momento da previs√£o. Isso pode acontecer quando a vari√°vel alvo √© alterada antes da previs√£o ser realizada, introduzindo assim um vi√©s nos resultados. Por exemplo, considere um modelo de classifica√ß√£o de spam em e-mails. Suponha que o objetivo seja prever se um e-mail √© spam ou n√£o com base no conte√∫do e nos atributos do e-mail. No entanto, durante o treinamento do modelo, a vari√°vel alvo (indicando se o e-mail √© spam ou n√£o) √© atualizada ap√≥s a an√°lise do conte√∫do do e-mail, e o modelo ent√£o, ter√° acesso a informa√ß√µes futuras que n√£o estariam dispon√≠veis no momento real da classifica√ß√£o. Isso pode levar a uma avalia√ß√£o enganosa do modelo, pois ele estar√° utilizando informa√ß√µes que n√£o seriam conhecidas no momento em que a classifica√ß√£o real seria realizada. Quando o modelo for aplicado em tempo real para classificar novos e-mails, ele n√£o ter√° acesso a essas informa√ß√µes futuras e sua capacidade de previs√£o ser√° comprometida, resultando em uma menor efic√°cia na detec√ß√£o de spam. 


![over](over.jpeg)

## Overfitting: Quando o modelo se ajusta demais aos dados de treinamento

Independente de sua causa, o vazamento de dados pode levar a um superajuste do modelo aos dados de treinamento, fen√¥meno conhecido como _overfitting_, resultando em um desempenho fraco em dados n√£o vistos. O modelo pode memorizar os padr√µes de vazamento e n√£o conseguir generalizar corretamente para novos dados. Al√©m disso, pode causar resultados inconsistentes e imprecisos, uma vez que informa√ß√µes irrelevantes ou incorretas s√£o utilizadas no processo de treinamento. Isso pode levar a decis√µes err√¥neas e impactar negativamente os resultados esperados.

## Como evitar o vazamento de dados nos modelos de machine learning?

Prevenir o vazamento de dados √© essencial para garantir a qualidade e a confiabilidade dos modelos de machine learning. Antes de come√ßar qualquer projeto de machine learning, √© fundamental ter um conhecimento profundo dos dados. Isso envolve entender a estrutura dos dados, sua qualidade, poss√≠veis vieses e a rela√ß√£o entre as vari√°veis. Ao conhecer os dados de forma abrangente, √© poss√≠vel identificar potenciais fontes de _data leakage_.


![train+test+samples](https://media4.giphy.com/media/zIOdLMZDcBDc2gk6vV/giphy.gif)  


#### Divis√£o adequada dos conjuntos de dados

Outro ponto que se deve levar em considera√ß√£o √© a correta divis√£o dos conjuntos de treinamento, valida√ß√£o e teste. Essa pr√°tica √© essencial para evitar o vazamento de dados. A t√©cnica mais comum √© usar uma divis√£o temporal, se for o caso, garantindo que os dados futuros n√£o sejam inclu√≠dos no conjunto de treinamento. Al√©m disso, √© importante ter um conjunto de valida√ß√£o para ajustar os hiperpar√¢metros do modelo e um conjunto de teste para avaliar seu desempenho final. Lembre-se que todas imputa√ß√µes de _missing values_ devem ser realizadas a partir de informa√ß√µes do **conjunto de treinamento**.

#### Feature engineering cuidadosa

A engenharia de recursos desempenha um papel cr√≠tico na cria√ß√£o de vari√°veis √∫teis para o modelo. No entanto, √© necess√°rio ter cuidado ao criar vari√°veis que n√£o estariam dispon√≠veis durante a aplica√ß√£o pr√°tica. √â importante garantir que todas as vari√°veis criadas sejam baseadas apenas em informa√ß√µes dispon√≠veis at√© o momento em que a previs√£o √© feita. 

#### Valida√ß√£o cruzada apropriada

A valida√ß√£o cruzada √© uma t√©cnica √∫til para avaliar o desempenho do modelo. No entanto, √© importante aplic√°-la corretamente, garantindo que os passos de pr√©-processamento, engenharia de recursos e modelagem sejam realizados separadamente para cada dobra da valida√ß√£o cruzada. Isso evita o vazamento de informa√ß√µes entre as dobras e produz resultados mais realistas.

## Em resumo...

O vazamento de dados representa um desafio oculto na an√°lise de dados e pode comprometer a precis√£o e a confiabilidade dos modelos de machine learning. No entanto, adotar estrat√©gias adequadas de preven√ß√£o de vazamentos pode ajudar a mitigar esses problemas e garantir a integridade dos modelos.

Ao compreender as causas do data leakage e adotar pr√°ticas adequadas de an√°lise de dados, as organiza√ß√µes podem obter resultados mais confi√°veis e maximizar o valor de seus projetos de machine learning.

A conscientiza√ß√£o sobre o data leakage √© essencial para os profissionais de an√°lise de dados e cientistas de dados. Ao adotar medidas proativas para prevenir o vazamento de dados, podemos construir modelos confi√°veis e tomar decis√µes mais informadas, impulsionando o sucesso das empresas e maximizando o valor dos dados.


At√© breve! üëã


